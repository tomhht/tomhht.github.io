<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://tomhht.github.io</id>
    <title>hello, world</title>
    <updated>2020-09-25T08:43:27.692Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://tomhht.github.io"/>
    <link rel="self" href="https://tomhht.github.io/atom.xml"/>
    <logo>https://tomhht.github.io/images/avatar.png</logo>
    <icon>https://tomhht.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, hello, world</rights>
    <entry>
        <title type="html"><![CDATA[学会提问]]></title>
        <id>https://tomhht.github.io/post/xue-hui-ti-wen/</id>
        <link href="https://tomhht.github.io/post/xue-hui-ti-wen/">
        </link>
        <updated>2020-09-24T06:18:22.000Z</updated>
        <summary type="html"><![CDATA[<p>读《学会提问》第十一版有感。</p>
]]></summary>
        <content type="html"><![CDATA[<p>读《学会提问》第十一版有感。</p>
<!-- more -->
<h1 id="2种思维">2种思维</h1>
<h2 id="海绵式思维">海绵式思维</h2>
<p>海纳百川，全盘接受。</p>
<h2 id="淘金式思维">淘金式思维</h2>
<p>海纳百川，弃其糟粕取其精华。</p>
<h1 id="2种批判性思维">2种批判性思维</h1>
<h2 id="弱势批判性思维">弱势批判性思维</h2>
<p>固执己见，找各种资源证明己见。</p>
<h2 id="强势批判性思维">强势批判性思维</h2>
<p>主张客观，依据各种资源综合分析出结论。</p>
<h1 id="2种论题">2种论题</h1>
<h2 id="描述性论述-descriptive-issues">描述性论述 descriptive issues</h2>
<p>关于”是什么“、”是否“的问题。</p>
<h2 id="规定性论题-prescriptive-issues">规定性论题 prescriptive issues</h2>
<p>关于”什么该/不该做“、”什么是对/错“、”什么是好/坏“的问题。</p>
<h1 id="找结论的方法">找结论的方法</h1>
<h2 id="找论题">找论题</h2>
<h2 id="找指示词">找指示词</h2>
<ul>
<li>因此（consequently）</li>
<li>表明（suggests that）</li>
<li>由此可知（therefore）</li>
<li>由此得出（thus）</li>
<li>因此可以断定（it follows that）</li>
<li>我要说的重点是（the point I'm trying to make is）</li>
<li>显示出（shows that）</li>
<li>证明（proves that）</li>
<li>告诉我们（indicates that）</li>
<li>问题的实质是（the truth of the matter is）</li>
</ul>
<h2 id="找篇头篇尾">找篇头篇尾</h2>
<h2 id="排除法">排除法</h2>
<p>以下是不可能作为结论的东西：</p>
<ul>
<li>例证</li>
<li>数据</li>
<li>定义</li>
<li>背景材料</li>
<li>证据</li>
</ul>
<h2 id="检查交流语境和作者背景">检查交流语境和作者背景</h2>
<h1 id="理由-结论-论证">理由 + 结论 = 论证</h1>
<p>只有结论的叫纯论点（mere opinion），无法评判其价值。</p>
<h1 id="理由">理由</h1>
<h2 id="通过提示词找理由">通过提示词找理由</h2>
<ul>
<li>由于（as a result of）</li>
<li>因为这个原因（for the reason that）</li>
<li>因为这个事实（because of the fact that）</li>
<li>鉴于（in view of）</li>
<li>由以下材料支撑（is supported by）</li>
<li>因为证据显示（because the evidence is）</li>
<li>研究显示（studies show）</li>
<li>第一、第二、第三（first...second...third）</li>
</ul>
<h2 id="理由的类型">理由的类型</h2>
<p>很多理由都是提供证据（evidence）的一些陈述。证据包括：</p>
<ul>
<li>事实</li>
<li>研究成果</li>
<li>生活实例</li>
<li>统计数据</li>
<li>专家意见</li>
<li>当事人证言</li>
<li>类比</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OpenStack安装调试记录]]></title>
        <id>https://tomhht.github.io/post/openstack-an-zhuang-diao-shi-ji-lu/</id>
        <link href="https://tomhht.github.io/post/openstack-an-zhuang-diao-shi-ji-lu/">
        </link>
        <updated>2020-09-20T06:39:47.000Z</updated>
        <summary type="html"><![CDATA[<p>非生产环境，仅学习用。</p>
]]></summary>
        <content type="html"><![CDATA[<p>非生产环境，仅学习用。</p>
<!-- more -->
<h1 id="实验环境">实验环境</h1>
<ol>
<li>Ubuntu Server 20.04 LTS</li>
<li>Ubuntu 20.04 LTS</li>
</ol>
<h1 id="准备工作">准备工作</h1>
<h2 id="内存配足了">内存配足了</h2>
<p>不管实机虚机，内存≥6G。<br>
血的教训，4G内存装一半就报错，本以为安装文件配置问题，结果偶然发现<code>Out of memory: Killed process 79546 (mysqld)</code>。记录查错的多种命令：</p>
<pre><code>sudo egrep -i -r 'killed process' /var/log
dmesg | grep -i 'out of memory'
sudo journalctl -kx | grep -i 'out of memory'
</code></pre>
<h2 id="创建用户-stack">创建用户 stack</h2>
<pre><code>sudo useradd -s /bin/bash -d /opt/stack -m stack
echo &quot;stack ALL=(ALL) NOPASSWD: ALL&quot; | sudo tee /etc/sudoers.d/stack
sudo su - stack
</code></pre>
<h2 id="下载devstack">下载DevStack</h2>
<pre><code>git clone http://git.trystack.cn/openstack/devstack
cd devstack
</code></pre>
<h2 id="修改pypi国内镜像">修改pypi国内镜像</h2>
<pre><code>pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
</code></pre>
<p>否则容易pip失败。</p>
<h2 id="修改ebtables的指向">修改ebtables的指向</h2>
<pre><code>sudo update-alternatives --set ebtables /usr/sbin/ebtables-legacy || true
</code></pre>
<p>否则对于Ubuntu 20.04会报错<code>table 'broute' is incompatible, use 'nft' tool</code>。<br>
据说是Ubuntu 20.04才会出现的问题，18.04无此问题。感谢<a href="https://www.journaldev.com/30037/install-openstack-ubuntu-devstack">How to Install OpenStack on Ubuntu 18.04 with DevStack</a>文后的回复者Gyan。</p>
<h1 id="安装devstack">安装DevStack</h1>
<h2 id="单节点模式single-node">单节点模式single-node</h2>
<h3 id="创建localconf文件">创建local.conf文件</h3>
<pre><code>cat &lt;&lt;EOF &gt; local.conf
[[local|localrc]]
HOST_IP=192.168.127.132
LOGFILE=/opt/stack/logs/stack.sh.log
ADMIN_PASSWORD=secret
DATABASE_PASSWORD=$ADMIN_PASSWORD
RABBIT_PASSWORD=$ADMIN_PASSWORD
SERVICE_PASSWORD=$ADMIN_PASSWORD
GIT_BASE=http://git.trystack.cn
NOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.git
SPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git
</code></pre>
<p>以下三行似乎没必要，没用他们也安装成功了，做个记录：</p>
<pre><code>Q_PLUGIN=ml2
ENABLE_TENANT_VLANS=True
ML2_VLAN_RANGES=physnet1:1000:2000
</code></pre>
<h3 id="开始安装">开始安装</h3>
<pre><code>./stack.sh
</code></pre>
<p>如遇到问题，跳至<a href="#Troubleshooting">Troubleshooting</a>。<br>
<strong>成功！</strong></p>
<pre><code>=========================
DevStack Component Timing
 (times are in seconds)  
=========================
wait_for_service      26
pip_install          136
apt-get                8
run_process           72
dbsync                45
apt-get-update         3
test_with_retry        3
osc                  196
-------------------------
Unaccounted time     657
=========================
Total runtime        1146



This is your host IP address: 192.168.0.109
This is your host IPv6 address: ::1
Horizon is now available at http://192.168.0.109/dashboard
Keystone is serving at http://192.168.0.109/identity/
The default users are: admin and demo
The password: secret

Services are running under systemd unit files.
For more information see: 
https://docs.openstack.org/devstack/latest/systemd.html

DevStack Version: victoria
Change: 1f8109ac29c6222fea2f02ffd487701de29e2355 Merge &quot;Further py2 cleanup for Fedora&quot; 2020-09-19 11:36:12 +0000
OS Version: Ubuntu 20.04 focal

2020-09-23 02:51:43.021 | stack.sh completed in 1148 seconds.
</code></pre>
<h2 id="多节点模式multi-node">多节点模式multi-node</h2>
<h3 id="配置ssh">配置ssh</h3>
<p>供stack访问各节点。</p>
<pre><code>mkdir ~/.ssh; chmod 700 ~/.ssh
echo &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCyYjfgyPazTvGpd8OaAvtU2utL8W6gWC4JdRS1J95GhNNfQd657yO6s1AH5KYQWktcE6FO/xNUC2reEXSGC7ezy+sGO1kj9Limv5vrvNHvF1+wts0Cmyx61D2nQw35/Qz8BvpdJANL7VwP/cFI/p3yhvx2lsnjFE3hN8xRB2LtLUopUSVdBwACOVUmH2G+2BWMJDjVINd2DPqRIA4Zhy09KJ3O1Joabr0XpQL0yt/I9x8BVHdAx6l9U0tMg9dj5+tAjZvMAFfye3PJcYwwsfJoFxC8w/SLtqlFX7Ehw++8RtvomvuipLdmWCy+T9hIkl+gHYE4cS3OIqXH7f49jdJf jesse@spacey.local&quot; &gt; ~/.ssh/authorized_keys
</code></pre>
<p>下面分cluster controller  和  compute node。</p>
<h3 id="cluster-controller">cluster controller</h3>
<h4 id="创建localconf文件-2">创建local.conf文件</h4>
<pre><code>cat &lt;&lt;EOF &gt; local.conf
[[local|localrc]]
HOST_IP=192.168.0.109
FIXED_RANGE=10.4.128.0/20
FLOATING_RANGE=192.168.0.128/25
LOGFILE=/opt/stack/logs/stack.sh.log
ADMIN_PASSWORD=secret
DATABASE_PASSWORD=$ADMIN_PASSWORD
RABBIT_PASSWORD=$ADMIN_PASSWORD
SERVICE_PASSWORD=$ADMIN_PASSWORD
GIT_BASE=http://git.trystack.cn
NOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.git
SPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git
Q_PLUGIN=ml2
ENABLE_TENANT_VLANS=True
ML2_VLAN_RANGES=physnet1:1000:2000
</code></pre>
<h4 id="开始安装-2">开始安装</h4>
<pre><code>./stack.sh
</code></pre>
<p>如遇到问题，跳至<a href="#Troubleshooting">Troubleshooting</a>。<br>
<strong>成功！</strong></p>
<pre><code>=========================
DevStack Component Timing
 (times are in seconds)  
=========================
wait_for_service      26
pip_install          172
apt-get               58
run_process           59
dbsync                46
apt-get-update         4
test_with_retry        3
osc                  227
-------------------------
Unaccounted time     533
=========================
Total runtime        1128



This is your host IP address: 192.168.0.109
This is your host IPv6 address: ::1
Horizon is now available at http://192.168.0.109/dashboard
Keystone is serving at http://192.168.0.109/identity/
The default users are: admin and demo
The password: secret

Services are running under systemd unit files.
For more information see: 
https://docs.openstack.org/devstack/latest/systemd.html

DevStack Version: victoria
Change: 1f8109ac29c6222fea2f02ffd487701de29e2355 Merge &quot;Further py2 cleanup for Fedora&quot; 2020-09-19 11:36:12 +0000
OS Version: Ubuntu 20.04 focal
</code></pre>
<h3 id="compute-node">compute node</h3>
<h4 id="创建localconf文件-3">创建local.conf文件</h4>
<pre><code>cat &lt;&lt;EOF &gt; local.conf
[[local|localrc]]
HOST_IP=192.168.0.110
FIXED_RANGE=10.4.128.0/20
FLOATING_RANGE=192.168.0.128/25
LOGFILE=/opt/stack/logs/stack.sh.log
ADMIN_PASSWORD=secret
DATABASE_PASSWORD=$ADMIN_PASSWORD
RABBIT_PASSWORD=$ADMIN_PASSWORD
SERVICE_PASSWORD=$ADMIN_PASSWORD
DATABASE_TYPE=mysql
SERVICE_HOST=192.168.0.109
MYSQL_HOST=$SERVICE_HOST
RABBIT_HOST=$SERVICE_HOST
GLANCE_HOSTPORT=$SERVICE_HOST:9292
ENABLED_SERVICES=n-cpu,q-agt,c-vol,placement-client
NOVA_VNC_ENABLED=True
NOVNCPROXY_URL=&quot;http://$SERVICE_HOST:6080/vnc_lite.html&quot;
VNCSERVER_LISTEN=$HOST_IP
VNCSERVER_PROXYCLIENT_ADDRESS=$VNCSERVER_LISTEN
GIT_BASE=http://git.trystack.cn
NOVNC_REPO=http://git.trystack.cn/kanaka/noVNC.git
SPICE_REPO=http://git.trystack.cn/git/spice/spice-html5.git
</code></pre>
<h1 id="troubleshooting">Troubleshooting</h1>
<ol>
<li><code>github etcd</code>无法下载，走梯子。</li>
</ol>
<pre><code>curl -x http://192.168.127.1:58591 -fsSL https://github.com/etcd-io/etcd/releases/download/v3.3.12/etcd-v3.3.12-linux-amd64.tar.gz -o /opt/stack/devstack/files/etcd-v3.3.12-linux-amd64.tar.gz
</code></pre>
<ol start="2">
<li>提示pip版本不够新<br>
出现如下警示，然后就报错停止。试着运行<code>./stack.sh</code>重装，应能解决。</li>
</ol>
<pre><code>WARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.
You should consider upgrading via the '/opt/stack/tempest/.tox/tempest/bin/python -m pip install --upgrade pip' command.
</code></pre>
<ol start="3">
<li>反复遇到<code>Failure creating NET_ID for private</code>问题<br>
清理以后再多装几次。</li>
</ol>
<pre><code>./unstack.sh
./clean.sh
./stack.sh
</code></pre>
<p>之前google baidu bing了n多，该有的<code>ML2_VLAN_RANGES=physnet1:1000:2000</code>、<code>vni_ranges = 1:1000</code>之类也都搞了，再安装依然报同样错。<strong>特别感谢</strong><a href="https://my.oschina.net/haitaohu/blog/3084104">通过devstack，在Vmware中使用Centos7快速安装体验openstack（单节点安装）</a>作者提到的卸载再装的方法。</p>
<blockquote>
<p>推测其他一些难解的问题也可以尝试该法。</p>
</blockquote>
<ol start="4">
<li>其他错误<br>
做好心理准备，安装过程可能产生各种错误，然后就自己停下来。如果不是上面几种错误，可以简单尝试重装1..2..n次，具体几次，是个玄学。</li>
</ol>
<!-- ## control-node
```
sudo ufw allow 80/tcp
sudo ufw allow 3306/tcp
``` -->
<hr>
<p>参考链接：<br>
<a href="https://docs.openstack.org/devstack/latest/">DevStack</a><br>
<a href="https://yangsijie666.github.io/2018/09/12/devstack%E5%AE%89%E8%A3%85R%E7%89%88/">openstack学习之devstack安装</a><br>
<a href="https://www.yunforum.net/group-topic-id-1561.html">devstack安装使用openstack常见问题与解决办法</a><br>
<a href="https://www.journaldev.com/30037/install-openstack-ubuntu-devstack">How to Install OpenStack on Ubuntu 18.04 with DevStack</a><br>
<a href="https://my.oschina.net/haitaohu/blog/3084104">通过devstack，在Vmware中使用Centos7快速安装体验openstack（单节点安装）</a><br>
<a href="http://git.trystack.cn/cgit">TryStack Git Mirror</a><br>
<a href="https://docs.openstack.org/devstack/latest/guides/multinode-lab.html">Multi-Node Lab</a><br>
<a href="https://bugs.launchpad.net/devstack/+bug/1726260">devstack fails while running ./stack.sh in master/queens in ubuntu 16.04 while starting n-cpu</a><br>
<a href="https://www.cnblogs.com/duanxz/p/10185946.html">Linux进程被杀掉（OOM killer），查看系统日志</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[干掉Win10顽固不化的某快速访问固定项]]></title>
        <id>https://tomhht.github.io/post/gan-diao-win10-wan-gu-bu-hua-de-mou-kuai-su-fang-wen-gu-ding-xiang/</id>
        <link href="https://tomhht.github.io/post/gan-diao-win10-wan-gu-bu-hua-de-mou-kuai-su-fang-wen-gu-ding-xiang/">
        </link>
        <updated>2020-09-15T00:59:03.000Z</updated>
        <summary type="html"><![CDATA[<p>快速访问里有个Documents死活无法取消固定，点了又说不存在，让删又删不了，lese。</p>
]]></summary>
        <content type="html"><![CDATA[<p>快速访问里有个Documents死活无法取消固定，点了又说不存在，让删又删不了，lese。</p>
<!-- more -->
<p>感谢参考链接的作者，该方法效若桴鼓。</p>
<blockquote>
<p>注意事项：该方法会删除快速访问里的所有内容，考虑清楚再动手。（我的本来就只有我的电脑和烦人的那项，所以果断kill）</p>
</blockquote>
<ol>
<li>拷贝<code>%APPDATA%\Microsoft\Windows\Recent\AutomaticDestinations</code>至 运行 或 文件夹地址栏，回车；</li>
<li>删除其中文件<code>f01b4d95cf55d32a.automaticDestinations-ms</code>。</li>
</ol>
<p>DONE，整个世界都清净了。</p>
<hr>
<p>参考链接：<br>
<a href="https://blog.csdn.net/yin0hao/article/details/88052343">Windows 10 快速访问异常:无法取消固定,的解决方法</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[helm安装kube-prometheus-stack]]></title>
        <id>https://tomhht.github.io/post/an-zhuang-prometheus-operator/</id>
        <link href="https://tomhht.github.io/post/an-zhuang-prometheus-operator/">
        </link>
        <updated>2020-09-13T09:45:34.000Z</updated>
        <summary type="html"><![CDATA[<p>众所周知的原因搞得安装起来太复杂了，并且helm的prometheus operator的chart项目还迁移过，更有点云里雾里。</p>
]]></summary>
        <content type="html"><![CDATA[<p>众所周知的原因搞得安装起来太复杂了，并且helm的prometheus operator的chart项目还迁移过，更有点云里雾里。</p>
<!-- more -->
<h1 id="创建专用namespace">创建专用namespace</h1>
<p>先创建个namespace来用。</p>
<pre><code>kubectl create namespace monitoring
</code></pre>
<h1 id="单独安装crd">单独安装CRD</h1>
<p>CRD就是Custom Resource Definition。<br>
本来应该是<code>helm install kube-prometheus-stack</code>的时候就能装，but as you know..<br>
通过科学上网，先下载yaml再说：</p>
<pre><code># 整齐点儿
mkdir -p ~/helm/prometheus-operator
cd ~/helm/prometheus-operator

# 下载yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_probes.yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_prometheusrules.yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml
curl -x http://192.168.127.1:58591 -fsSLO https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/example/prometheus-operator-crd/monitoring.coreos.com_thanosrulers.yaml

# 安装
kubectl apply -f .
</code></pre>
<h1 id="安装-kube-prometheus-stack">安装 kube-prometheus-stack</h1>
<p>kube-prometheus-stack基于prometheus-operator制作，并集成了依赖</p>
<ul>
<li>stable/kube-state-metrics</li>
<li>stable/prometheus-node-exporter</li>
<li>grafana/grafana</li>
</ul>
<pre><code># 安装
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --set prometheusOperator.createCustomResource=false -n monitoring
# 查看安装情况
kubectl -n monitoring get deployments
NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE
kube-prometheus-stack-grafana              1/1     1            1           4h30m
kube-prometheus-stack-kube-state-metrics   1/1     1            1           4h30m
kube-prometheus-stack-operator             1/1     1            1           4h30m

kubectl -n monitoring get pods -owide
NAME                                                        READY   STATUS    RESTARTS   AGE     IP                NODE           NOMINATED NODE   READINESS GATES
alertmanager-kube-prometheus-stack-alertmanager-0           2/2     Running   2          4h14m   10.244.1.32       mini-ubuntu    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-grafana-8b85d667c-5w8sn               2/2     Running   4          4h32m   10.244.2.23       mini-centos    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-kube-state-metrics-5cf575d8f8-6m7jt   1/1     Running   1          4h32m   10.244.1.33       mini-ubuntu    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-operator-65fbd96bdb-9zhmz             2/2     Running   6          4h32m   10.244.2.21       mini-centos    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-prometheus-node-exporter-68sxv        1/1     Running   2          4h32m   192.168.127.133   mini-centos    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-prometheus-node-exporter-864w9        1/1     Running   1          4h32m   192.168.127.132   ubuntuserver   &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-prometheus-node-exporter-nr274        1/1     Running   1          4h32m   192.168.127.134   mini-ubuntu    &lt;none&gt;           &lt;none&gt;
prometheus-kube-prometheus-stack-prometheus-0               3/3     Running   6          4h14m   10.244.2.22       mini-centos    &lt;none&gt;           &lt;none&gt;
</code></pre>
<blockquote>
<p>遇到问题往后看。</p>
</blockquote>
<h1 id="安装过程的troubleshooting">安装过程的Troubleshooting</h1>
<p>安装过程各种报错，当然主要是镜像pull不下来，尤其是<code>quay.io</code>的镜像。(我的挺奇怪，居然自己pull成功了几个<code>quay.io</code>)</p>
<h2 id="排查问题">排查问题</h2>
<pre><code>kubectl -n monitoring describe pods prometheus-kube-prometheus-stack-prometheus-0

Events:
  Type     Reason   Age                    From                  Message
  ----     ------   ----                   ----                  -------
  Normal   Pulling  60m (x4 over 83m)      kubelet, mini-centos  Pulling image &quot;quay.io/coreos/prometheus-config-reloader:v0.38.1&quot;
  Warning  Failed   58m (x4 over 79m)      kubelet, mini-centos  Failed to pull image &quot;quay.io/coreos/prometheus-config-reloader:v0.38.1&quot;: rpc error: code = Unknown desc = context canceled
  Warning  Failed   58m (x4 over 79m)      kubelet, mini-centos  Error: ErrImagePull
  Normal   Pulling  58m (x5 over 100m)     kubelet, mini-centos  Pulling image &quot;quay.io/prometheus/prometheus:v2.18.2&quot;
  Normal   Pulled   47m                    kubelet, mini-centos  Successfully pulled image &quot;quay.io/coreos/prometheus-config-reloader:v0.38.1&quot; in 1m11.597994512s
  Warning  Failed   22m (x11 over 83m)     kubelet, mini-centos  Error: ErrImagePull
  Normal   BackOff  13m (x130 over 56m)    kubelet, mini-centos  Back-off pulling image &quot;quay.io/prometheus/prometheus:v2.18.2&quot;
  Warning  Failed   8m15s (x145 over 56m)  kubelet, mini-centos  Error: ImagePullBackOff
  Warning  Failed   3m13s (x14 over 83m)   kubelet, mini-centos  Failed to pull image &quot;quay.io/prometheus/prometheus:v2.18.2&quot;: rpc error: code = Unknown desc = context canceled
</code></pre>
<h2 id="解决">解决</h2>
<p><code>google prometheus v2.18.2</code>居然发现<code>docker hub</code>里有，于是在<code>mini-centos</code>主机上：</p>
<pre><code>docker pull prom/prometheus:v2.18.2
v2.18.2: Pulling from prom/prometheus
0f8c40e1270f: Already exists 
626a2a3fee8c: Already exists 
dde61fbb486b: Already exists 
22b936665674: Downloading [=================================================&gt; ]  20.66MB/20.76MB
b9cb37b79bc0: Download complete 
a14008f52cd5: Download complete 
c89901a55493: Waiting 
</code></pre>
<p>就定这儿了，遂祭起重启docker大法：</p>
<pre><code>sudo systemctl restart docker
</code></pre>
<p>重启完后，接着：</p>
<pre><code>docker pull prom/prometheus:v2.18.2
v2.18.2: Pulling from prom/prometheus
0f8c40e1270f: Already exists 
626a2a3fee8c: Already exists 
dde61fbb486b: Already exists 
22b936665674: Pull complete 
b9cb37b79bc0: Pull complete 
a14008f52cd5: Pull complete 
c89901a55493: Pull complete 
6caddd047c54: Pull complete 
ddd1779460e5: Pull complete 
f65cc1a7f25d: Pull complete 
4be7bc9429a7: Pull complete 
2d296d78b122: Pull complete 
Digest: sha256:4d3303d1eb424e345cf48969bb7575d4d58472ad783ac41ea07fba92686f7ef5
Status: Downloaded newer image for prom/prometheus:v2.18.2
docker.io/prom/prometheus:v2.18.2
</code></pre>
<p>再检查：</p>
<pre><code>kubectl -n monitoring get pods -owide
NAME                                                        READY   STATUS    RESTARTS   AGE     IP                NODE           NOMINATED NODE   READINESS GATES
alertmanager-kube-prometheus-stack-alertmanager-0           2/2     Running   2          4h14m   10.244.1.32       mini-ubuntu    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-grafana-8b85d667c-5w8sn               2/2     Running   4          4h32m   10.244.2.23       mini-centos    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-kube-state-metrics-5cf575d8f8-6m7jt   1/1     Running   1          4h32m   10.244.1.33       mini-ubuntu    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-operator-65fbd96bdb-9zhmz             2/2     Running   6          4h32m   10.244.2.21       mini-centos    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-prometheus-node-exporter-68sxv        1/1     Running   2          4h32m   192.168.127.133   mini-centos    &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-prometheus-node-exporter-864w9        1/1     Running   1          4h32m   192.168.127.132   ubuntuserver   &lt;none&gt;           &lt;none&gt;
kube-prometheus-stack-prometheus-node-exporter-nr274        1/1     Running   1          4h32m   192.168.127.134   mini-ubuntu    &lt;none&gt;           &lt;none&gt;
prometheus-kube-prometheus-stack-prometheus-0               3/3     Running   6          4h14m   10.244.2.22       mini-centos    &lt;none&gt;           &lt;none&gt;
</code></pre>
<p>全都ready了。<br>
如有其他pull问题，应该可以如法炮制。</p>
<h1 id="暴露服务">暴露服务</h1>
<h2 id="查看服务">查看服务</h2>
<pre><code>kubectl -n monitoring get svc
NAME                                             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
alertmanager-operated                            ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   4h16m
kube-prometheus-stack-alertmanager               ClusterIP   10.101.245.140   &lt;none&gt;        9093/TCP                     4h34m
kube-prometheus-stack-grafana                    ClusterIP   10.106.193.98    &lt;none&gt;        80/TCP                       4h34m
kube-prometheus-stack-kube-state-metrics         ClusterIP   10.108.208.70    &lt;none&gt;        8080/TCP                     4h34m
kube-prometheus-stack-operator                   ClusterIP   10.110.217.187   &lt;none&gt;        8080/TCP,443/TCP             4h34m
kube-prometheus-stack-prometheus                 ClusterIP   10.104.189.224   &lt;none&gt;        9090/TCP                     4h34m
kube-prometheus-stack-prometheus-node-exporter   ClusterIP   10.102.189.12    &lt;none&gt;        9100/TCP                     4h34m
prometheus-operated                              ClusterIP   None             &lt;none&gt;        9090/TCP                     4h16m
</code></pre>
<h2 id="改nodeport">改NodePort</h2>
<p>把下面服务的type改成NodePort：</p>
<pre><code>kubectl -n monitoring edit svc kube-prometheus-stack-prometheus
kubectl -n monitoring edit svc kube-prometheus-stack-alertmanager
kubectl -n monitoring edit svc kube-prometheus-stack-grafana

kubectl -n monitoring get svc
NAME                                             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
alertmanager-operated                            ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   4h51m
kube-prometheus-stack-alertmanager               NodePort    10.101.245.140   &lt;none&gt;        9093:31386/TCP               5h9m
kube-prometheus-stack-grafana                    NodePort    10.106.193.98    &lt;none&gt;        80:30835/TCP                 5h9m
kube-prometheus-stack-kube-state-metrics         ClusterIP   10.108.208.70    &lt;none&gt;        8080/TCP                     5h9m
kube-prometheus-stack-operator                   ClusterIP   10.110.217.187   &lt;none&gt;        8080/TCP,443/TCP             5h9m
kube-prometheus-stack-prometheus                 NodePort    10.104.189.224   &lt;none&gt;        9090:30098/TCP               5h9m
kube-prometheus-stack-prometheus-node-exporter   ClusterIP   10.102.189.12    &lt;none&gt;        9100/TCP                     5h9m
prometheus-operated                              ClusterIP   None             &lt;none&gt;        9090/TCP                     4h51m
</code></pre>
<h1 id="访问prometheus">访问prometheus</h1>
<p>打开http://192.168.127.132:30098/targets，一部分up一部分down，点Unhealthy<br>
<img src="https://tomhht.github.io/post-images/1600245194725.png" alt="unhealthy" loading="lazy"></p>
<h2 id="解决down的部分">解决down的部分</h2>
<h3 id="etcd的down">etcd的down</h3>
<blockquote>
<p>搞了1.5天，搜到的各种资料都无法适用，结合各家之言，再无数次尝试才勉强有结果。</p>
</blockquote>
<pre><code>sudo vim /etc/kubernetes/manifests/etcd.yaml
# 找到
- --listen-client-urls=https://127.0.0.1:2379,https://192.168.127.132:2379
# 修改为
- --listen-client-urls=https://0.0.0.0:2379,http://0.0.0.0:2379
# 重启全部container（实际上是停止命令，k8s会自动全部启动）
docker stop $(docker ps -q)
</code></pre>
<blockquote>
<p>挺奇葩的一点是，down变为up后，我又改回原配置，再重启全部container，依然保持up状态，存疑ing。</p>
</blockquote>
<h3 id="kube-scheduler的down">kube-scheduler的down</h3>
<pre><code>sudo vim /etc/kubernetes/manifests/kube-scheduler.yaml
//改为- --bind-address=0.0.0.0
//删行- --port=0
//稍等几秒即可
</code></pre>
<blockquote>
<p>这个要特别感谢度娘帮我搜到的<a href="https://llovewxm1314.blog.csdn.net/article/details/108458197">解决kubernetes:v1.18.6-1.19.0 get cs127.0.0.1 connection refused错误</a>。一个port你说你默认等于0干啥，你自己都unhealthy你说prometheus哪儿能监控得到。感谢原作者，n个小时后终于破案。</p>
</blockquote>
<h3 id="kube-controller-manager的down">kube-controller-manager的down</h3>
<p>修改套路同kube-scheduler。</p>
<pre><code>sudo vim /etc/kubernetes/manifests/kube-controller-manager.yaml
//改为- --bind-address=0.0.0.0
//删行- --port=0
//稍等几秒即可
</code></pre>
<h3 id="node-exporter的down">node-exporter的down</h3>
<pre><code>kubectl -n monitoring edit ds kube-prometheus-stack-prometheus-node-exporter
//删掉 hostNetwork: true 一行
//稍等几秒即可
//还没尝试helm给参数的方式，有机会试试override the hostNetwork setting using a values file with -f option
</code></pre>
<blockquote>
<p>特别感谢google来的<a href="https://vividcode.io/fix-context-deadline-exceeded-error-in-prometheus-operator/">Fix Context Deadline Exceeded Error in Prometheus Operator</a></p>
</blockquote>
<h3 id="kube-proxy的down尚未搞定">kube-proxy的down（尚未搞定）</h3>
<p>暂时跳过，快崩溃了（人），下面的方法用了根本不行，google bing baidu齐上阵，前前后后得搞了1天。好心的哪位，可否帮忙留言个正解？</p>
<pre><code># 可能用得到的指令
kubectl -n kube-system edit cm kube-proxy  //改metricsBindAddress: 为 0.0.0.0:10249
kubectl delete pod -l k8s-app=kube-proxy -n kube-system
// 按上面的操作，完全没效果，晕
sudo netstat -ntlp | grep kube
sudo ss -ntlp | grep kube
</code></pre>
<blockquote>
<p>这是第一个开始搞的，结果其他都搞定了，它还岿然不动。</p>
</blockquote>
<h1 id="grafana篇章">Grafana篇章</h1>
<p>kube-prometheus-stack里已经自带Grafana，因此无需安装。</p>
<h2 id="访问grafana">访问grafana</h2>
<pre><code>kubectl -n monitoring get svc //找到grafana的端口，然后浏览器访问http://IP:PORT
</code></pre>
<p><strong>用户名/密码是？</strong><br>
一堆说<code>admin/admin</code>的，然而这个环境不适用。</p>
<pre><code>用户名：admin
密码：prom-operator
</code></pre>
<blockquote>
<p>特别感谢<a href="https://devstack.in/2020/05/25/deploy-prometheus-operator-with-helm3-and-private-registry/">Deploy Prometheus Operator with Helm3 and Private Registry</a></p>
</blockquote>
<p><strong>漂亮</strong><br>
<img src="https://tomhht.github.io/post-images/1600249518889.png" alt="UI" loading="lazy"><br>
<strong>在Manage里随便选一个</strong><br>
<img src="https://tomhht.github.io/post-images/1600250887179.png" alt="magic" loading="lazy"><br>
<img src="https://tomhht.github.io/post-images/1600249787073.png" alt="gorgeous" loading="lazy"></p>
<h1 id="日志篇章efk">日志篇章EFK</h1>
<p>Elasticsearch+Fluentd+Kibana<br>
大部分参考<a href="https://www.qikqiak.com/post/install-efk-stack-on-k8s/">一文彻底搞定 EFK 日志收集</a>。</p>
<h2 id="几处调整">几处调整</h2>
<h3 id="elasticsearch-statefulsetyaml">elasticsearch-statefulset.yaml</h3>
<pre><code># 执行之前，给nodes打es=log标签
kubectl label nodes --all es=log

#  修改containers的image，因为docker.elastic.co的慢，pull容易失败
      image: elasticsearch:7.9.1

# 因为是测试，没有rook ceph，因此就替换volumn为emptydir
#  volumeClaimTemplates: 段落改为了：
      volumes:
      - name: data
        emptyDir: {}
</code></pre>
<blockquote>
<p>用kubectl -n logging get pods观察，发现statefulset的pod是one by one搞的。部署过程不快，看了下，elasticsearch的镜像700多MB。</p>
</blockquote>
<hr>
<p>参考链接：<br>
<a href="https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack">https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack</a><br>
<a href="https://github.com/prometheus-operator/prometheus-operator">https://github.com/prometheus-operator/prometheus-operator</a><br>
<a href="https://github.com/prometheus-operator/kube-prometheus">https://github.com/prometheus-operator/kube-prometheus</a><br>
<a href="https://www.bookstack.cn/read/kubernetes-learning-0.2.0/docs-58.Prometheus%20Operator.md">https://www.bookstack.cn/read/kubernetes-learning-0.2.0/docs-58.Prometheus%20Operator.md</a><br>
<a href="https://www.qikqiak.com/post/prometheus-operator-monitor-etcd/">https://www.qikqiak.com/post/prometheus-operator-monitor-etcd/</a><br>
<a href="https://blog.fleeto.us/post/node-downtime/">https://blog.fleeto.us/post/node-downtime/</a><br>
<a href="https://llovewxm1314.blog.csdn.net/article/details/108458197">解决kubernetes:v1.18.6-1.19.0 get cs127.0.0.1 connection refused错误</a><br>
<a href="https://vividcode.io/fix-context-deadline-exceeded-error-in-prometheus-operator/">Fix Context Deadline Exceeded Error in Prometheus Operator</a><br>
<a href="https://devstack.in/2020/05/25/deploy-prometheus-operator-with-helm3-and-private-registry/">Deploy Prometheus Operator with Helm3 and Private Registry</a><br>
<a href="https://www.qikqiak.com/post/install-efk-stack-on-k8s/">一文彻底搞定 EFK 日志收集</a><br>
稍后阅读：<br>
<a href="https://www.qikqiak.com/post/k8s-hpa-usage/">Kubernetes HPA 使用详解</a><br>
<a href="https://blog.51cto.com/14143894/2438026">Kubernetes运维之使用Prometheus全方位监控K8S</a><br>
<a href="https://www.cnblogs.com/williamjie/p/10836799.html">Linux操作系统load average过高，kworker占用较多cpu</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[最小化安装centos和ubuntu之后的配置]]></title>
        <id>https://tomhht.github.io/post/zui-xiao-hua-an-zhuang-centos-hou-de-she-zhi/</id>
        <link href="https://tomhht.github.io/post/zui-xiao-hua-an-zhuang-centos-hou-de-she-zhi/">
        </link>
        <updated>2020-09-10T10:54:55.000Z</updated>
        <summary type="html"><![CDATA[<p>最小化安装centos 8后的设置。</p>
]]></summary>
        <content type="html"><![CDATA[<p>最小化安装centos 8后的设置。</p>
<!-- more -->
<h1 id="更换国内源">更换国内源</h1>
<p>参考<a href="/post/pei-zhi-ubuntu-he-centos-qing-hua-yuan">配置清华源</a></p>
<h1 id="安装epel">安装epel</h1>
<pre><code>sudo yum install epel-release
# 更换清华源
sudo sed -e 's!^metalink=!#metalink=!g' \
    -e 's!^#baseurl=!baseurl=!g' \
    -e 's!//download\.fedoraproject\.org/pub!//mirrors.tuna.tsinghua.edu.cn!g' \
    -e 's!http://mirrors\.tuna!https://mirrors.tuna!g' \
    -i /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel-testing.repo
sudo yum makecache
</code></pre>
<h1 id="更新软件">更新软件</h1>
<pre><code>yum check-update
sudo yum upgrade
</code></pre>
<h1 id="设置时区和ntp">设置时区和NTP</h1>
<pre><code>timedatectl set-timezone Asia/Shanghai
sudo yum install chrony
sudo systemctl enable --now chronyd
timedatectl status
</code></pre>
<h1 id="自动补全">自动补全</h1>
<pre><code>sudo yum install bash-completion
source ~/.bashrc
</code></pre>
<h1 id="配置vim">配置vim</h1>
<pre><code>sudo vim /etc/vim/vimrc.local
# 粘贴下面的内容进去
set showcmd
set showmatch
set ignorecase
set smartcase
set incsearch
set autowrite
set hidden
set nocompatible
set number
set autoindent
set smartindent
set tabstop=2
set shiftwidth=2
set autoread
set wildmenu
set expandtab
if has(&quot;vms&quot;)
set nobackup
else
set backup
endif
filetype indent on
filetype on
</code></pre>
<p>保存后，执行<code>source /etc/vim/vimrc</code>。</p>
<h1 id="安装wget">安装wget</h1>
<pre><code>sudo yum -y install wget
</code></pre>
<h1 id="其他有用的记录">其他有用的记录</h1>
<pre><code># 找程序所属的包
yum whatprovides netstat
</code></pre>
<hr>
<p>参考链接：<br>
<a href="https://www.cnblogs.com/fengdejiyixx/p/11592417.html">Centos和Ubuntu系统最小化安装基础命令</a><br>
<a href="https://linuxconfig.org/ubuntu-20-04-server-installation">Ubuntu 20.04 Server Installation</a><br>
<a href="https://juejin.im/post/6844904149822210056">写给工程师的 Ubuntu 20.04 最佳配置指南</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用virsh删除kvm虚拟机]]></title>
        <id>https://tomhht.github.io/post/shi-yong-virsh-shan-chu-kvm-xu-ni-ji/</id>
        <link href="https://tomhht.github.io/post/shi-yong-virsh-shan-chu-kvm-xu-ni-ji/">
        </link>
        <updated>2020-09-10T06:21:16.000Z</updated>
        <summary type="html"><![CDATA[<p>发现libvirt/images下有个qcow2文件挺大，于是想用virsh安全删掉。</p>
]]></summary>
        <content type="html"><![CDATA[<p>发现libvirt/images下有个qcow2文件挺大，于是想用virsh安全删掉。</p>
<!-- more -->
<h1 id="列出虚拟机">列出虚拟机</h1>
<p>开始没用sudo，结果啥都没有，明明记得之前搞过俩呢。</p>
<pre><code>sudo virsh list --all
 Id    Name                           State
----------------------------------------------------
 -     vm1                            shut off
 -     vm2                            shut off
</code></pre>
<h1 id="检查虚拟机配置">检查虚拟机配置</h1>
<pre><code>sudo virsh dumpxml vm1 | grep 'source file'
    &lt;source file='/var/lib/libvirt/images/cirros-0.5.1-x86_64-disk.img'/&gt;
    &lt;source file='/var/lib/libvirt/images/vm1.qcow2'/&gt; #要删这个
</code></pre>
<h1 id="编辑配置">编辑配置</h1>
<p>确保该虚拟机未运行。删除配置中挂载<code>vm1.qcow2</code>的段落。</p>
<pre><code>sudo virsh edit vm1
# 删除这段
    &lt;disk type='file' device='disk'&gt;
      &lt;driver name='qemu' type='qcow2'/&gt;
      &lt;source file='/var/lib/libvirt/images/vm1.qcow2'/&gt;
      &lt;target dev='hda' bus='ide'/&gt;
      &lt;address type='drive' controller='0' bus='0' target='0' unit='1'/&gt;
    &lt;/disk&gt; 
</code></pre>
<h1 id="删除文件">删除文件</h1>
<pre><code>sudo rm /var/lib/libvirt/images/vm1.qcow2
</code></pre>
<p>搞定。</p>
<hr>
<p>参考链接：<br>
<a href="https://huataihuang.gitbooks.io/cloud-atlas/content/virtual/kvm/startup/in_action/delete_a_running_vm_on_kvm.html">使用virsh删除运行的KVM VM · Cloud Atlas</a><br>
<a href="https://www.jianshu.com/p/5111134452a8">KVM磁盘扩容和添加</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[在Ubuntu上用snap安装Helm]]></title>
        <id>https://tomhht.github.io/post/zai-ubuntu-shang-yong-snap-an-zhuang-helm/</id>
        <link href="https://tomhht.github.io/post/zai-ubuntu-shang-yong-snap-an-zhuang-helm/">
        </link>
        <updated>2020-09-07T08:45:29.000Z</updated>
        <summary type="html"><![CDATA[<p>命令挺简单，就是速度很感人。</p>
]]></summary>
        <content type="html"><![CDATA[<p>命令挺简单，就是速度很感人。</p>
<!-- more -->
<h1 id="安装">安装</h1>
<pre><code>sudo snap install helm --classic
</code></pre>
<p>安装过慢的解决办法还没尝试，参考链接先记录下来了，先谢谢原作者。</p>
<blockquote>
<p>据官方说明，Helm 3已经不需要Tiller了，所以其他参考资料上安装Tiller的步骤直接跳过。</p>
</blockquote>
<h1 id="配置">配置</h1>
<h2 id="自动补全">自动补全</h2>
<pre><code>echo 'source &lt;(helm completion bash)' &gt;&gt;~/.bashrc
source ~/.bashrc #使配置立刻生效
</code></pre>
<hr>
<p>参考链接：<br>
<a href="https://helm.sh/">Helm官方</a><br>
<a href="https://kuricat.com/gist/snap-install-too-slow-zmbjy">snap install 过慢 的解决方法 @Kurisu</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[k8s测试mysql挂载nfs遇到的问题]]></title>
        <id>https://tomhht.github.io/post/pei-zhi-nfs/</id>
        <link href="https://tomhht.github.io/post/pei-zhi-nfs/">
        </link>
        <updated>2020-09-06T07:50:41.000Z</updated>
        <summary type="html"><![CDATA[<p>学习nfs的配置，并测试k8s部署mysql挂载nfs的方式。</p>
]]></summary>
        <content type="html"><![CDATA[<p>学习nfs的配置，并测试k8s部署mysql挂载nfs的方式。</p>
<!-- more -->
<h1 id="配置nfs">配置nfs</h1>
<h2 id="ubuntu">Ubuntu</h2>
<p>先将参考链接放这儿。<a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-20-04">How To Set Up an NFS Mount on Ubuntu 20.04</a></p>
<h2 id="centos">CentOS</h2>
<p><a href="https://qizhanming.com/blog/2018/08/08/how-to-install-nfs-on-centos-7">CentOS 7 下 yum 安装和配置 NFS</a></p>
<h1 id="k8s测试遇到的问题">k8s测试遇到的问题</h1>
<h2 id="镜像pull不下来">镜像pull不下来</h2>
<p><strong>问题描述</strong><br>
测试mysql挂载nfs失败了n次，一开始是镜像pull不下来。<br>
<strong>解决</strong><br>
后来添加阿里云加速器后重启node上的docker <code>sudo systemctl restart docker.service</code>解决了pull的问题。</p>
<h2 id="pod遇到backoff的错误">pod遇到backoff的错误</h2>
<p><strong>问题描述</strong><br>
pull下来了还是运行失败，pod总是显示backoff <code>Back-off restarting failed container</code>的错误，通过<code>kubectl logs &lt;mysql pod的名字&gt;</code>发现<code>chown: changing ownership of '/var/lib/mysql/': Operation not permitted</code>错误。<br>
<strong>解决</strong><br>
nfs配置文件<code>/etc/exports</code>里，加上了<code>no_root_squash</code>的选项。</p>
<hr>
<p>参考链接：<br>
<a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-20-04">How To Set Up an NFS Mount on Ubuntu 20.04</a><br>
<a href="https://qizhanming.com/blog/2018/08/08/how-to-install-nfs-on-centos-7">CentOS 7 下 yum 安装和配置 NFS</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kubernetes busybox nslookup提示无法解析的问题]]></title>
        <id>https://tomhht.github.io/post/kubernetes-busybox-nslookup-ti-shi-wu-fa-jie-xi-de-wen-ti/</id>
        <link href="https://tomhht.github.io/post/kubernetes-busybox-nslookup-ti-shi-wu-fa-jie-xi-de-wen-ti/">
        </link>
        <updated>2020-09-05T07:43:38.000Z</updated>
        <summary type="html"><![CDATA[<p>使用默认版本的busybox会出现nslookup提示无法解析的问题。使用1.28.3版本即可解决。</p>
]]></summary>
        <content type="html"><![CDATA[<p>使用默认版本的busybox会出现nslookup提示无法解析的问题。使用1.28.3版本即可解决。</p>
<!-- more -->
<p>症状：</p>
<pre><code>kubectl run busybox --rm -it --image=busybox /bin/sh
/ # nslookup httpd-svc
Server:		10.96.0.10
Address:	10.96.0.10:53

** server can't find httpd-svc.default.svc.cluster.local: NXDOMAIN

*** Can't find httpd-svc.svc.cluster.local: No answer
*** Can't find httpd-svc.cluster.local: No answer
*** Can't find httpd-svc.default.svc.cluster.local: No answer
*** Can't find httpd-svc.svc.cluster.local: No answer
*** Can't find httpd-svc.cluster.local: No answer
</code></pre>
<p>解决：</p>
<pre><code>kubectl run busybox --rm -it --image=busybox:1.28.3 /bin/sh
If you don't see a command prompt, try pressing enter.
/ # nslookup httpd-svc
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      httpd-svc
Address 1: 10.108.142.200 httpd-svc.default.svc.cluster.local
</code></pre>
<hr>
<p>参考链接：<br>
<a href="https://www.cnblogs.com/vincenshen/p/9751193.html">https://www.cnblogs.com/vincenshen/p/9751193.html</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第一次正式开车]]></title>
        <id>https://tomhht.github.io/post/di-yi-ci-zheng-shi-kai-che/</id>
        <link href="https://tomhht.github.io/post/di-yi-ci-zheng-shi-kai-che/">
        </link>
        <updated>2020-09-05T05:44:19.000Z</updated>
        <summary type="html"><![CDATA[<p>拿了本大半年了，昨天第一次正式开车。</p>
]]></summary>
        <content type="html"><![CDATA[<p>拿了本大半年了，昨天第一次正式开车。</p>
<!-- more -->
<p>太刺激了。画龙、剐蹭、油合离门，应有尽有。科三考了3次才过，考过后抽奖中了一个陪练机会，跟着教练开了趟易县（同练的还有其他学员）。这就是之前全部的开车经历了。<br /><br>
昨天因为要接侄子，学校在一个鸟不拉屎的地方，约不到车，所以硬着头皮把家里的车开出来了。首先找地方掉头，光顾着看后面，结果车头蹭人家墙上了，引得人家出来检查。<br /><br>
好不容易掉好头，跟别的车交汇，一闪躲，噌，又是一声，之前左边，这次右边。<br /><br>
继续前行，后来想想，居然当时心态没崩。<br /><br>
画龙前行，志玲姐姐忽然来一句右转立刻左转，我这路口到底怎么走啊，遂决定直接左转，进了左转车道等红灯，发现右转后走10米果然有左转路，WTF。左转车道硬着头皮左转完了，终于找到一个路口直接掉头，走上了康庄大道。<br /><br>
转完了突然道路宽阔了起来，路上也没几辆车，于是let's go，4档的干活，这感觉就是乌龟爬到了兔子身上。<br /><br>
到校后，等了几个钟头，中途又开着出去练练手，接上娃后返程的路途也算有惊无险，终于平安的运送回家。庆幸的是这一路没有倒车入库、侧方停车之类的技术活。万幸。</p>
]]></content>
    </entry>
</feed>